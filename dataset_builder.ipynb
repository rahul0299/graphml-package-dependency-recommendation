{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:36:05.895171Z",
     "start_time": "2024-11-13T05:36:05.443149Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:36:07.170691Z",
     "start_time": "2024-11-13T05:36:07.102721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_package_space_from_project_json(filepath):\n",
    "    package_space = set()\n",
    "    project_data = json.load(open(filepath))\n",
    "    for _, deps in project_data.items():\n",
    "        for pkg in deps.keys():\n",
    "            if pkg.startswith(\"npm:\"):\n",
    "                pkg = pkg[4:]\n",
    "            package_space.add(pkg)\n",
    "            \n",
    "    return package_space"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of packages: 16784\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def create_package_list():\n",
    "    res = requests.get(\"https://gist.github.com/anvaka/8e8fa57c7ee1350e3491\")\n",
    "    if res.status_code == 200:\n",
    "        parsed_html = BeautifulSoup(res.content, \"html.parser\")\n",
    "        selector = \"#gistcomment-4447488 > div.edit-comment-hide > task-lists > div > p:nth-child(3)\"\n",
    "        package_list = parsed_html.select(selector)\n",
    "        with open(\"./playground/package_list.txt\", \"w\") as f:\n",
    "            f.write(package_list[0].text)\n",
    "            \n",
    "def load_package_list():\n",
    "    if not os.path.exists(\"./playground/package_list.txt\"):\n",
    "        create_package_list()\n",
    "    else:\n",
    "        with open(\"./playground/package_list.txt\", \"r\") as f:\n",
    "            return [text for text in f.read().splitlines()]\n",
    "    \n",
    "def create_package_space_from_github_gist():\n",
    "    # packages = load_package_list()\n",
    "    # print(len(packages))\n",
    "    return set(load_package_list())\n",
    "    \n",
    "                \n",
    "print(len(create_package_space_from_github_gist()))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pkg_space = create_package_space_from_project_json(\"./GithubScrape/Data/40_Projects/append_dependencies_40_1.json\")\n",
    "print(\"Number of packages:\", len(pkg_space))"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T12:59:37.879625Z",
     "start_time": "2024-11-09T12:59:37.836319Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of packages: 11243\n"
     ]
    }
   ],
   "execution_count": 83,
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def convert_time_to_epoch(timestamp):\n",
    "    timestamp = timestamp.replace('Z', '+00:00')\n",
    "    timestamp = datetime.fromisoformat(timestamp)\n",
    "    return datetime.strftime(timestamp, '%s')\n",
    "    "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:36:13.308685Z",
     "start_time": "2024-11-13T05:36:13.292256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_package_data(package, base_url=\"https://registry.npmjs.org/\", max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            res = requests.get(base_url + package)\n",
    "            data = res.json()\n",
    "            \n",
    "            if res.status_code == 200:\n",
    "                if 'dist-tags' not in data:\n",
    "                    print(f\"{package} is unpublished\")\n",
    "                    return {}\n",
    "            \n",
    "                latest_version = data[\"dist-tags\"][\"latest\"]\n",
    "                \n",
    "                package_details = {\n",
    "                    \"latestVersion\": latest_version,\n",
    "                    \"keywords\": data.get(\"keywords\", []),\n",
    "                    \"publishTime\": convert_time_to_epoch(data[\"time\"][latest_version]),\n",
    "                    \"description\": data.get(\"description\", \"\"),\n",
    "                    \"creationDate\": data[\"time\"][\"created\"],\n",
    "                    \"numberOfVersions\": len(data[\"versions\"]),\n",
    "                    \"dependencies\": data[\"versions\"][latest_version].get(\"dependencies\", {}), \n",
    "                    \"devDependencies\": data[\"versions\"][latest_version].get(\"devDependencies\", {}), \n",
    "                    \"peerDependencies\": data[\"versions\"][latest_version].get(\"peerDependencies\", {}), \n",
    "                }\n",
    "                return package_details\n",
    "            \n",
    "            else:\n",
    "                print(f\"{package} failed with status code {res.status_code}\")\n",
    "                return {}\n",
    "                \n",
    "        except requests.exceptions.ConnectionError as ce:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Failed to fetch {package} due to connection error: attempt {attempt + 1}\")\n",
    "            else:\n",
    "                print(\"Failed to fetch {package}: max attempts exceeded\")\n",
    "                return {}\n",
    "        except Exception as e:\n",
    "            print(\"EXCEPTION OCCURED\", package, e)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:47:59.002052Z",
     "start_time": "2024-11-13T05:36:16.439603Z"
    }
   },
   "cell_type": "code",
   "source": "fetch_package_data(\"@types/recordrtc\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer 0:   0%|          | 0/16784 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "942adb73726243ab9c47865723dd3c46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] for install-test: 'dist-tags'. Package Unpublished\n",
      "[ERROR] for vuex-vue3: 'dist-tags'. Package Unpublished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 1:   0%|          | 0/1497 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfe35765d45a432fa19e90c3dcde66a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Layer 2:   0%|          | 0/809 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b2c5a8f397242d2a17c0cf166d49773"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get data for @tsparticles/interaction-particles-collisions: attempt 1\n",
      "Failed to get data for @sanity/preview-kit-compat: attempt 1\n",
      "Failed to get data for @sanity/mutate: attempt 1\n",
      "Failed to get data for @vercel/stega: attempt 1\n",
      "Failed to get data for @sanity/comlink: attempt 1\n",
      "Failed to get data for use-effect-event: attempt 1\n",
      "Failed to get data for @stdlib/complex-float32-base-add: attempt 1Failed to get data for @stdlib/complex-float32-base-assert: attempt 1\n",
      "\n",
      "Failed to get data for @stdlib/complex-float32-base-mul: attempt 1\n",
      "Failed to get data for json-alexander: attempt 1\n",
      "Failed to get data for sync-message-port: attempt 1\n",
      "Failed to get data for babel-plugin-react-require: attempt 1\n",
      "Failed to get data for @babel/plugin-proposal-pipeline-operator: attempt 1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def limit_package_space(full_space, n):\n",
    "    limit_space = set()\n",
    "    for _ in range(n):\n",
    "        limit_space.add(full_space.pop())\n",
    "    return limit_space"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_package_space(max_workers=20, max_iters=2, test_mode=False, src='project'):\n",
    "    \n",
    "    package_space = []\n",
    "    \n",
    "    if src == 'github':\n",
    "        package_space = create_package_space_from_github_gist()\n",
    "    elif src == 'project':\n",
    "        package_space = create_package_space_from_project_json(\"./GithubScrape/Data/40_Projects/append_dependencies_40_1.json\")\n",
    "\n",
    "    \n",
    "    if test_mode:\n",
    "        package_space = limit_package_space(package_space, 20)\n",
    "    \n",
    "    fetched = set()\n",
    "    package_features = dict()\n",
    "    dep_graph = dict()\n",
    "    \n",
    "    feat_lock = threading.Lock()\n",
    "    graph_lock = threading.Lock()\n",
    "    fetched_lock = threading.Lock()\n",
    "    \n",
    "    data_fields = [\n",
    "        \"latest_version\",\n",
    "        \"keywords\",\n",
    "        \"publish_time\",\n",
    "        \"description\",\n",
    "        \"creation_date\", \n",
    "        \"number_of_versions\"\n",
    "    ]\n",
    "    \n",
    "    # THIS CODE IS FOR IF WE WANT TO INCLUDE MULTIPLE DEPENDENCY TYPES\n",
    "    # ----------------------------------------------------------------\n",
    "    # dep_types = [\n",
    "    #     (\"dependencies\", \"PROD\"), \n",
    "    #     (\"devDependencies\", \"DEV\"), \n",
    "    #     (\"peerDependencies\", \"PEER\")\n",
    "    # ]\n",
    "    \n",
    "    next_iter = set()\n",
    "    next_iter.update(package_space)\n",
    "    # print(next_iter)\n",
    "    \n",
    "    curr_iter = 1\n",
    "    \n",
    "    while (max_iters == -1 and len(next_iter) > 0) or curr_iter <= max_iters:\n",
    "        package_set, next_iter = next_iter, set()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = { executor.submit(fetch_package_data, package): package for package in package_set }\n",
    "            \n",
    "            try: \n",
    "                for future in tqdm(as_completed(futures), total=len(futures), desc=f'Iteration {curr_iter}'):\n",
    "                    pkg = futures[future]\n",
    "                    package_data = future.result()\n",
    "                    \n",
    "                    with fetched_lock:\n",
    "                        fetched.add(pkg)\n",
    "                    \n",
    "                    if package_data != {}:\n",
    "                        with feat_lock, graph_lock:\n",
    "                            package_features[pkg] = {field: package_data[field] for field in data_fields}\n",
    "                            dep_graph[pkg] = package_data[\"dependencies\"]\n",
    "                            next_iter.update(package_data[\"dependencies\"].keys())\n",
    "    \n",
    "                            # THIS CODE IS FOR IF WE WANT TO INCLUDE MULTIPLE DEPENDENCY TYPES\n",
    "                            # ----------------------------------------------------------------\n",
    "                            # dep = dict()\n",
    "                            # for d_type, code in dep_types:\n",
    "                            #     for d,v in package_data[d_type].items():\n",
    "                            #         dep[d] = (v, code)\n",
    "                            #         \n",
    "                            # dep_graph[pkg] = dep\n",
    "                            # \n",
    "                            # next_iter.update(package_data[\"dependencies\"].keys())\n",
    "                            # next_iter.update(package_data[\"devDependencies\"].keys())\n",
    "                            # next_iter.update(package_data[\"peerDependencies\"].keys())\n",
    "                            \n",
    "                            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        next_iter.difference_update(fetched)\n",
    "        \n",
    "        print(f\"Next Iteration - {curr_iter + 1}: {len(next_iter)} packages\")\n",
    "        curr_iter += 1\n",
    "    \n",
    "    return package_features, dep_graph\n",
    "            "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "feats, graph = build_package_space(max_iters=-1)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:48:47.357224Z",
     "start_time": "2024-11-13T05:48:47.303706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# divide into scoped and unscoped packages\n",
    "scoped = []\n",
    "unscoped = []\n",
    "for package in feats.keys():\n",
    "    if package.find(\"@\") != -1:\n",
    "        scoped.append((package, feats[package][\"creationDate\"]))\n",
    "    else:\n",
    "        unscoped.append(package)\n",
    "print(f'scoped: {len(scoped)}\\tunscoped: {len(unscoped)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoped: 7558\tunscoped: 10724\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:43:56.240607Z",
     "start_time": "2024-11-08T18:43:56.225904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks = []\n",
    "for i in range(0, len(unscoped), 128):\n",
    "    chunks.append(unscoped[i:i + 128])\n",
    "print(len(chunks))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:43:57.849649Z",
     "start_time": "2024-11-08T18:43:57.841379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CAN GET DOWNLOAD COUNTS FOR UNSCOPED PACKAGES IN BULK\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_all_time_download_counts_bulk(packages, format=\"%Y-%m-%d\"):\n",
    "    start_date = datetime(day=10, month=1, year=2015).date()\n",
    "    curr_date = datetime.now().date()\n",
    "    \n",
    "    intervals = []\n",
    "    while start_date < curr_date:\n",
    "        interval_end = min(start_date + timedelta(days=365), curr_date)\n",
    "        intervals.append(f'{start_date.strftime(format)}:{interval_end.strftime(format)}')\n",
    "        start_date = interval_end + timedelta(days=1)\n",
    "        \n",
    "    download_counts = defaultdict(int)\n",
    "    for interval in intervals:\n",
    "        url = f\"https://api.npmjs.org/downloads/point/{interval}/{','.join(packages)}\"\n",
    "        res = requests.get(url)\n",
    "        if res.status_code == 200:\n",
    "            download_data = res.json()\n",
    "            for package in packages:\n",
    "                download_counts[package] += download_data[package][\"downloads\"]\n",
    "    \n",
    "    return download_counts\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:44:53.864502Z",
     "start_time": "2024-11-08T18:44:02.489169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = { executor.submit(get_all_time_download_counts_bulk, chunk): chunk for chunk in chunks }\n",
    "    \n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Getting download counts for unscoped packages\"):\n",
    "        for package, count in future.result().items():\n",
    "            feats[package][\"download_count\"] = count"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Getting download counts for unscoped packages:   0%|          | 0/59 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4822cf538f44f9d980176c0e8159ba8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:45:52.420877Z",
     "start_time": "2024-11-08T18:45:51.771719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# FOR UNSCOPED, update download function to process one package concurrently\n",
    "def get_year_downloads(package, interval):\n",
    "    url = f\"https://api.npmjs.org/downloads/point/{interval}/{package}\"\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        return res.json()[\"downloads\"]\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_all_time_download_count_concurrent(package, creation_date, format=\"%Y-%m-%d\", max_workers=3):\n",
    "    create_date = creation_date.replace('Z', '+00:00')\n",
    "    create_date = datetime.fromisoformat(create_date)\n",
    "    \n",
    "    start_date = max(datetime(day=10, month=1, year=2015).date(), create_date.date())\n",
    "    curr_date = datetime.now().date()\n",
    "    \n",
    "    intervals = []\n",
    "    while start_date < curr_date:\n",
    "        interval_end = min(start_date + timedelta(days=547), curr_date)\n",
    "        intervals.append(f'{start_date.strftime(format)}:{interval_end.strftime(format)}')\n",
    "        start_date = interval_end + timedelta(days=1)\n",
    "            \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = { executor.submit(get_year_downloads, package, interval): interval for interval in intervals }\n",
    "        download_count = 0\n",
    "\n",
    "        for future in futures:\n",
    "            download_count += future.result()\n",
    "\n",
    "        return download_count\n",
    "\n",
    "# test function\n",
    "count = get_all_time_download_count_concurrent(\"semver\", \"2011-02-12T00:20:25.690Z\")\n",
    "print(f'{count:,}')\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49,999,748,223\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T18:45:55.439867Z",
     "start_time": "2024-11-08T18:45:55.422208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_package_download_count(package, date, max_retries=3, max_workers=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            download_count = get_all_time_download_count_concurrent(package, date, max_workers=max_workers)\n",
    "            return download_count\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f'Failed getting count for {package}: attempt {attempt + 1}')\n",
    "            else:\n",
    "                print(f'Failed getting count for {package}: max retries exceeded')\n",
    "    return -1\n",
    "\n",
    "def get_download_counts_scoped_concurrent(packages, max_retries=3, max_workers=2, max_sub_workers=3):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = { executor.submit(get_package_download_count, package, date, max_workers=max_sub_workers): package for package, date in packages }\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Scoped Packages\"):\n",
    "            package = futures[future]\n",
    "            download_count = future.result()\n",
    "            feats[package][\"download_count\"] = download_count\n",
    "            "
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:07:43.485885Z",
     "start_time": "2024-11-08T18:46:01.144020Z"
    }
   },
   "cell_type": "code",
   "source": "get_download_counts_scoped_concurrent(scoped, max_workers=3, max_sub_workers=3)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scoped Packages:   0%|          | 0/4923 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78c43b07bab0409db795450e126c100e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed getting count for @visx/shape: 1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:07.345580Z",
     "start_time": "2024-11-13T05:49:07.244107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"./dataset/dep-graph.json\", mode=\"w\") as file:\n",
    "    json.dump(graph, file, indent=4)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:08.747811Z",
     "start_time": "2024-11-13T05:49:08.578787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"./dataset/package-features.json\", mode=\"w\") as file:\n",
    "    json.dump(feats, file, indent=4)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:05.470721Z",
     "start_time": "2024-11-13T05:49:05.463156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(feats.keys()))\n",
    "print(len(graph.keys()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18282\n",
      "18282\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:11.535395Z",
     "start_time": "2024-11-13T05:49:11.427042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "edges = []\n",
    "\n",
    "for package, deps in graph.items():\n",
    "    if len(deps) > 0:\n",
    "        for dep, version in deps.items():\n",
    "            edges.append((package, dep, version))\n",
    "\n",
    "headers = ['package', 'dependency', 'version']\n",
    "df = pd.DataFrame(edges, columns=headers)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    package                     dependency version\n",
       "0  read-pkg  @types/normalize-package-data  ^2.4.3\n",
       "1  read-pkg         normalize-package-data  ^6.0.0\n",
       "2  read-pkg                     parse-json  ^8.0.0\n",
       "3  read-pkg                      type-fest  ^4.6.0\n",
       "4  read-pkg                  unicorn-magic  ^0.1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>dependency</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>read-pkg</td>\n",
       "      <td>@types/normalize-package-data</td>\n",
       "      <td>^2.4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read-pkg</td>\n",
       "      <td>normalize-package-data</td>\n",
       "      <td>^6.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>read-pkg</td>\n",
       "      <td>parse-json</td>\n",
       "      <td>^8.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>read-pkg</td>\n",
       "      <td>type-fest</td>\n",
       "      <td>^4.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read-pkg</td>\n",
       "      <td>unicorn-magic</td>\n",
       "      <td>^0.1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:13.316026Z",
     "start_time": "2024-11-13T05:49:13.303313Z"
    }
   },
   "cell_type": "code",
   "source": "len(df)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52738"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:15.235457Z",
     "start_time": "2024-11-13T05:49:15.136871Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"./dataset/dep-graph.csv\", index=False)",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "feat_data = []\n",
    "headers = ['package', 'latest_version', 'keywords', 'publish_time', 'description', 'creation_date', 'number_of_versions', 'download_count']\n",
    "for package, feats in feats.items():\n",
    "    feat_data.append([package] + list(feats.values()))\n",
    "\n",
    "feat_df = pd.DataFrame(feat_data, columns=headers)\n",
    "feat_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T19:08:06.573704Z",
     "start_time": "2024-11-08T19:08:06.506450Z"
    }
   },
   "cell_type": "code",
   "source": "feat_df.to_csv(\"./dataset/package-feats.csv\", index=False)",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T03:56:23.133083Z",
     "start_time": "2024-11-09T03:56:23.115757Z"
    }
   },
   "cell_type": "code",
   "source": "len(feat_df)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12370"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pagerank"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "dep_df = pd.read_csv(\"./dataset/dep-graph.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:30.756295Z",
     "start_time": "2024-11-13T05:49:30.603151Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "sources = set(dep_df['package'].unique())\n",
    "deps = set(dep_df['dependency'].unique())\n",
    "pkg_space = sources.union(deps)\n",
    "\n",
    "print(\"Unique packages in packages column\", len(sources))\n",
    "print(\"Unique packages in dependency column\", len(deps))\n",
    "print(\"Total unique\", len(pkg_space))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T09:30:04.751556Z",
     "start_time": "2024-11-13T09:30:04.717679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique packages in packages column 11553\n",
      "Unique packages in dependency column 13159\n",
      "Total unique 16508\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T05:49:35.395274Z",
     "start_time": "2024-11-13T05:49:34.666501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "no_out = {p for p, d in graph.items() if len(d) == 0}\n",
    "print(\"Nodes with 0 out-degree:\", len(no_out))\n",
    "\n",
    "with_in = set()\n",
    "for dependencies in graph.values():\n",
    "    with_in.update(dependencies)\n",
    "\n",
    "no_in = no_out - with_in\n",
    "\n",
    "print(\"Nodes with 0 in-degree and 0 out-degree:\", len(no_in))\n",
    "\n",
    "json_str = json.dumps(json.load(open(\"./playground/dep-graph.json\")))\n",
    "from_original = [p for p in no_in if json_str.find(p) != -1]\n",
    "print(\"Nodes with 0 in- and out-degree from source:\", len(from_original))"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# build adjacency matrix\n",
    "G = nx.from_pandas_edgelist(dep_df, source='package', target='dependency', create_using=nx.DiGraph)\n",
    "adj_matrix_sparse = csr_matrix(nx.adjacency_matrix(G))\n",
    "print(\"Adjacency Matrix shape:\", adj_matrix_sparse.shape)\n",
    "print(\"G:\", G)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Perform Pagerank\n",
    "ranks = nx.pagerank(G, alpha=0.25)\n",
    "ranks = list(ranks.items())\n",
    "ranks.sort(key=lambda x: x[1], reverse=True)\n",
    "ranks[:10]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://gist.github.com/anvaka/8e8fa57c7ee1350e3491\")\n",
    "\n",
    "full_pagerank = []\n",
    "\n",
    "if res.status_code != 200:\n",
    "    print(\"Request failed\")\n",
    "else:\n",
    "    parsed_html = BeautifulSoup(res.content, \"html.parser\")\n",
    "    github_pagerank = parsed_html.select(\"#file-03-pagerank-md-readme > article > ol > li\")\n",
    "    full_pagerank = [(html.find('a').text, float(html.text.split(\" - \")[1])) for html in github_pagerank]\n",
    "    \n",
    "full_pagerank[:10]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare how many packages appear in both\n",
    "rank_set = set([p for p,c in ranks[:1000]])\n",
    "full_set = set([p for p,c in full_pagerank])\n",
    "print(f\"Number of common packages: {len(rank_set.intersection(full_set))}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "count = 0\n",
    "for pkg, score in full_pagerank:\n",
    "    if pkg not in pkg_space:\n",
    "        count += 1\n",
    "        print(pkg)\n",
    "        \n",
    "print(f\"-------------\\nCount = {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
